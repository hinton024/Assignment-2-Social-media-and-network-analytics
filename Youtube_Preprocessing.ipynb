{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdb28a7",
   "metadata": {},
   "source": [
    "### Importing the Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcc6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "import nltk\n",
    "from langdetect import detect, LangDetectException\n",
    "import contractions\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec09f7",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing\n",
    "#### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b470b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Published at</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category ID</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 ICONIC David Beckham goals you'll NEVER forget</td>\n",
       "      <td>oTpTVqJX8ho</td>\n",
       "      <td>2023-12-11T16:01:00Z</td>\n",
       "      <td>10 of the best Premier League goals scored by ...</td>\n",
       "      <td>17</td>\n",
       "      <td>627</td>\n",
       "      <td>[Favourite David Beckham goal?, Goals before I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Beckham SURPRISES Thierry Henry, Jamie C...</td>\n",
       "      <td>wFDSJuqg0Vk</td>\n",
       "      <td>2024-09-17T19:56:02Z</td>\n",
       "      <td>David Beckham surprised Kate Abdo, Jamie Carra...</td>\n",
       "      <td>17</td>\n",
       "      <td>1822</td>\n",
       "      <td>[MY HERO!!üòÇüòÇüòÇ, As if David lets his mom cut hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Beckham Embraces the Moment While Eating...</td>\n",
       "      <td>igmUnkx0fBw</td>\n",
       "      <td>2024-08-29T15:00:45Z</td>\n",
       "      <td>David Beckham takes on the Hot Ones gauntlet f...</td>\n",
       "      <td>24</td>\n",
       "      <td>4265</td>\n",
       "      <td>[Yet further evidence that David Beckham is on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Beckham on Spice Girls Reuniting for Vic...</td>\n",
       "      <td>rniYjUoNbOU</td>\n",
       "      <td>2024-05-09T06:00:23Z</td>\n",
       "      <td>David talks about his honey, owning the Miami ...</td>\n",
       "      <td>23</td>\n",
       "      <td>771</td>\n",
       "      <td>[Amazing performance mate&amp;#39;s, changed game....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unbelievable David beckham 3 balls into a tras...</td>\n",
       "      <td>2lvRv2mnYLU</td>\n",
       "      <td>2011-04-08T06:48:00Z</td>\n",
       "      <td>You be the judge of this Pepsi video with LA G...</td>\n",
       "      <td>17</td>\n",
       "      <td>3653</td>\n",
       "      <td>[Ÿáÿ∞Ÿá ŸÖÿπÿ¨ÿ≤ÿ© ÿ≥ÿØÿØ ŸÉÿßŸÑÿ∫ŸàŸÑŸÅ ÿßŸÅÿ∂ŸÑ, ÿ®ŸäŸÉŸáÿßŸÖ ÿßŸàŸÇŸÅ Ÿáÿ∞Ÿá ÿß...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Video ID  \\\n",
       "0  10 ICONIC David Beckham goals you'll NEVER forget  oTpTVqJX8ho   \n",
       "1  David Beckham SURPRISES Thierry Henry, Jamie C...  wFDSJuqg0Vk   \n",
       "2  David Beckham Embraces the Moment While Eating...  igmUnkx0fBw   \n",
       "3  David Beckham on Spice Girls Reuniting for Vic...  rniYjUoNbOU   \n",
       "4  Unbelievable David beckham 3 balls into a tras...  2lvRv2mnYLU   \n",
       "\n",
       "           Published at                                        Description  \\\n",
       "0  2023-12-11T16:01:00Z  10 of the best Premier League goals scored by ...   \n",
       "1  2024-09-17T19:56:02Z  David Beckham surprised Kate Abdo, Jamie Carra...   \n",
       "2  2024-08-29T15:00:45Z  David Beckham takes on the Hot Ones gauntlet f...   \n",
       "3  2024-05-09T06:00:23Z  David talks about his honey, owning the Miami ...   \n",
       "4  2011-04-08T06:48:00Z  You be the judge of this Pepsi video with LA G...   \n",
       "\n",
       "  Category ID Comment Count                                           Comments  \n",
       "0          17           627  [Favourite David Beckham goal?, Goals before I...  \n",
       "1          17          1822  [MY HERO!!üòÇüòÇüòÇ, As if David lets his mom cut hi...  \n",
       "2          24          4265  [Yet further evidence that David Beckham is on...  \n",
       "3          23           771  [Amazing performance mate&#39;s, changed game....  \n",
       "4          17          3653  [Ÿáÿ∞Ÿá ŸÖÿπÿ¨ÿ≤ÿ© ÿ≥ÿØÿØ ŸÉÿßŸÑÿ∫ŸàŸÑŸÅ ÿßŸÅÿ∂ŸÑ, ÿ®ŸäŸÉŸáÿßŸÖ ÿßŸàŸÇŸÅ Ÿáÿ∞Ÿá ÿß...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('DB_youtube.json', 'r', encoding='utf-8') as file:\n",
    "    youtube = json.load(file)\n",
    "\n",
    "# Converting the data into a DataFrame \n",
    "df = pd.DataFrame(youtube)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca478b75",
   "metadata": {},
   "source": [
    "#### Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950cfc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "Title            0\n",
      "Video ID         0\n",
      "Published at     0\n",
      "Description      0\n",
      "Category ID      0\n",
      "Comment Count    0\n",
      "Comments         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62594702",
   "metadata": {},
   "source": [
    "#### Check for Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e279e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates based on Video ID\n",
    "duplicates = df.duplicated(subset=['Video ID']).sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Drop duplicates if any\n",
    "df.drop_duplicates(subset=['Video ID'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c6782",
   "metadata": {},
   "source": [
    "#### Advance Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9072371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for clean text\n",
    "def clean_text(text):\n",
    "    # Removing URLs and special characters, convert to lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Function to detect if the text is in English\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f59573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out non-English titles, descriptions, and comments\n",
    "df['Cleaned_Title'] = df['Title'].apply(lambda x: clean_text(str(x)) if is_english(str(x)) else '')\n",
    "df['Cleaned_Description'] = df['Description'].apply(lambda x: clean_text(str(x)) if is_english(str(x)) else '')\n",
    "\n",
    "# cleaning and filtering each comment within the list\n",
    "df['Cleaned_Comments'] = df['Comments'].apply(lambda comments: [clean_text(comment) for comment in comments if is_english(comment)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6fb005",
   "metadata": {},
   "source": [
    "#### Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc68264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand contractions for each column separately\n",
    "df['Expanded_Title'] = df['Cleaned_Title'].apply(contractions.fix)\n",
    "df['Expanded_Description'] = df['Cleaned_Description'].apply(contractions.fix)\n",
    "df['Expanded_Comments'] = df['Cleaned_Comments'].apply(lambda comments: [contractions.fix(comment) for comment in comments])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b06a4e",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb4773a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the cleaned text\n",
    "df['Title_Tokens'] = df['Cleaned_Title'].apply(word_tokenize)\n",
    "df['Description_Tokens'] = df['Cleaned_Description'].apply(word_tokenize)\n",
    "df['Comments_Tokens'] = df['Cleaned_Comments'].apply(lambda comments: [word_tokenize(comment) for comment in comments])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714247e5",
   "metadata": {},
   "source": [
    "#### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0ff672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "df['Title_Tokens'] = df['Title_Tokens'].apply(remove_stopwords)\n",
    "df['Description_Tokens'] = df['Description_Tokens'].apply(remove_stopwords)\n",
    "df['Comments_Tokens'] = df['Comments_Tokens'].apply(lambda comments: [remove_stopwords(comment) for comment in comments])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0deb1",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a8b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "df['Title_Tokens'] = df['Title_Tokens'].apply(lemmatize_tokens)\n",
    "df['Description_Tokens'] = df['Description_Tokens'].apply(lemmatize_tokens)\n",
    "df['Comments_Tokens'] = df['Comments_Tokens'].apply(lambda comments: [lemmatize_tokens(comment) for comment in comments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21ac83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Data:\n",
      "                                               Title  \\\n",
      "0  10 ICONIC David Beckham goals you'll NEVER forget   \n",
      "1  David Beckham SURPRISES Thierry Henry, Jamie C...   \n",
      "2  David Beckham Embraces the Moment While Eating...   \n",
      "3  David Beckham on Spice Girls Reuniting for Vic...   \n",
      "4  Unbelievable David beckham 3 balls into a tras...   \n",
      "\n",
      "                                       Cleaned_Title  \\\n",
      "0                                                      \n",
      "1  david beckham surprises thierry henry jamie ca...   \n",
      "2  david beckham embraces the moment while eating...   \n",
      "3  david beckham on spice girls reuniting for vic...   \n",
      "4  unbelievable david beckham  balls into a trash...   \n",
      "\n",
      "                                        Title_Tokens  \\\n",
      "0                                                 []   \n",
      "1  [david, beckham, surprise, thierry, henry, jam...   \n",
      "2  [david, beckham, embrace, moment, eating, spic...   \n",
      "3  [david, beckham, spice, girl, reuniting, victo...   \n",
      "4        [unbelievable, david, beckham, ball, trash]   \n",
      "\n",
      "                                         Description  \\\n",
      "0  10 of the best Premier League goals scored by ...   \n",
      "1  David Beckham surprised Kate Abdo, Jamie Carra...   \n",
      "2  David Beckham takes on the Hot Ones gauntlet f...   \n",
      "3  David talks about his honey, owning the Miami ...   \n",
      "4  You be the judge of this Pepsi video with LA G...   \n",
      "\n",
      "                                 Cleaned_Description  \\\n",
      "0  of the best premier league goals scored by for...   \n",
      "1  david beckham surprised kate abdo jamie carrag...   \n",
      "2  david beckham takes on the hot ones gauntlet f...   \n",
      "3  david talks about his honey owning the miami f...   \n",
      "4  you be the judge of this pepsi video with la g...   \n",
      "\n",
      "                                  Description_Tokens  \\\n",
      "0  [best, premier, league, goal, scored, former, ...   \n",
      "1  [david, beckham, surprised, kate, abdo, jamie,...   \n",
      "2  [david, beckham, take, hot, one, gauntlet, fir...   \n",
      "3  [david, talk, honey, owning, miami, football, ...   \n",
      "4  [judge, pepsi, video, la, galaxy, star, david,...   \n",
      "\n",
      "                                            Comments  \\\n",
      "0  [Favourite David Beckham goal?, Goals before I...   \n",
      "1  [MY HERO!!üòÇüòÇüòÇ, As if David lets his mom cut hi...   \n",
      "2  [Yet further evidence that David Beckham is on...   \n",
      "3  [Amazing performance mate&#39;s, changed game....   \n",
      "4  [Ÿáÿ∞Ÿá ŸÖÿπÿ¨ÿ≤ÿ© ÿ≥ÿØÿØ ŸÉÿßŸÑÿ∫ŸàŸÑŸÅ ÿßŸÅÿ∂ŸÑ, ÿ®ŸäŸÉŸáÿßŸÖ ÿßŸàŸÇŸÅ Ÿáÿ∞Ÿá ÿß...   \n",
      "\n",
      "                                    Cleaned_Comments  \\\n",
      "0  [goals before i was bornbeckham, clearly not j...   \n",
      "1  [as if david lets his mom cut his hair, how hi...   \n",
      "2  [yet further evidence that david beckham is on...   \n",
      "3  [amazing performance mates changed game and fa...   \n",
      "4  [its cgi and been debunked  its an ad for peps...   \n",
      "\n",
      "                                     Comments_Tokens  \n",
      "0  [[goal, bornbeckham], [clearly, pretty, face],...  \n",
      "1  [[david, let, mom, cut, hair], [high, bar, the...  \n",
      "2  [[yet, evidence, david, beckham, one, iconic, ...  \n",
      "3  [[amazing, performance, mate, changed, game, f...  \n",
      "4  [[cgi, debunked, ad, pepsi], [bruhh, always, s...  \n"
     ]
    }
   ],
   "source": [
    "# Printing the processed data\n",
    "processed_columns = ['Title', 'Cleaned_Title', 'Title_Tokens', 'Description', 'Cleaned_Description', 'Description_Tokens', 'Comments', 'Cleaned_Comments', 'Comments_Tokens']\n",
    "print(\"\\nProcessed Data:\")\n",
    "print(df[processed_columns].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d8aea",
   "metadata": {},
   "source": [
    "#### Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359e53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "# Function to process text: tokenize, remove stopwords, and lemmatize\n",
    "def process_text(text, lemmatizer, stopwords_set):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords_set]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd93c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 most common terms:\n",
      "beckham: 156\n",
      "david: 126\n",
      "like: 83\n",
      "man: 48\n",
      "one: 47\n",
      "football: 41\n",
      "love: 41\n",
      "time: 41\n",
      "world: 39\n",
      "player: 39\n",
      "show: 34\n",
      "u: 33\n",
      "game: 33\n",
      "goal: 32\n",
      "league: 31\n",
      "ra: 31\n",
      "beckhams: 31\n",
      "england: 30\n",
      "even: 29\n",
      "legend: 29\n",
      "real: 29\n",
      "year: 28\n",
      "video: 27\n",
      "best: 26\n",
      "get: 26\n",
      "kick: 25\n",
      "would: 25\n",
      "great: 25\n",
      "look: 25\n",
      "dont: 24\n",
      "he: 24\n",
      "know: 23\n",
      "subscribe: 23\n",
      "messi: 23\n",
      "really: 22\n",
      "never: 22\n",
      "well: 22\n",
      "free: 21\n",
      "make: 21\n",
      "good: 21\n",
      "im: 21\n",
      "victoria: 21\n",
      "people: 21\n",
      "new: 21\n",
      "thats: 20\n",
      "got: 20\n",
      "still: 20\n",
      "jimmy: 20\n",
      "see: 20\n",
      "match: 19\n"
     ]
    }
   ],
   "source": [
    "term_freq_counter = Counter()\n",
    "\n",
    "# Processing each row in the DataFrame and update term frequency counts\n",
    "for _, row in df.iterrows(): \n",
    "    tokens_title = process_text(row['Cleaned_Title'], lemmatizer, stopwords_set)\n",
    "    tokens_description = process_text(row['Cleaned_Description'], lemmatizer, stopwords_set)\n",
    "    tokens_comments = [word for comment in row['Cleaned_Comments'] for word in process_text(comment, lemmatizer, stopwords_set)]\n",
    "\n",
    "    term_freq_counter.update(tokens_title)\n",
    "    term_freq_counter.update(tokens_description)\n",
    "    term_freq_counter.update(tokens_comments)\n",
    "\n",
    "# Display the most common terms\n",
    "freq_num = 50  # Number of most frequent terms to display\n",
    "print(f\"Top {freq_num} most common terms:\")\n",
    "for term, count in term_freq_counter.most_common(freq_num):\n",
    "    print(f\"{term}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d198f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
